Kulveen's LLM QA Chatbot Builder
================================

An interactive and modular chatbot system that leverages Large Language Models (LLMs) for document-based question answering. This project supports data preparation, model fine-tuning, evaluation, and real-time inference â€” all wrapped in an intuitive Gradio interface.

==================================================
ğŸŒŸ Features
--------------------------------------------------
- ğŸ“„ Data Collection via Web UI (fine-tuning & test sets)
- ğŸ›  Fine-tune LLMs like Mistral, Zephyr, LLaMA, Phi, Flan-T5, or custom models
- ğŸ‘¨â€âš–ï¸ Human Evaluation dashboard for rating model-generated answers
- ğŸ’¬ Inference tab with RAG (Retrieval Augmented Generation) for live Q&A
- ğŸ§  Embedding Fine-tuning using various loss functions
- ğŸš€ Deployment-ready interface and model export options

==================================================
ğŸ—‚ Project Structure
--------------------------------------------------
src/
â”œâ”€â”€ inference.py            â†’ RAG pipeline and inference logic
â”œâ”€â”€ full_UI.py              â†’ Gradio Blocks interface
â”œâ”€â”€ fine_tune_file/         â†’ Scripts for training specific models
â”œâ”€â”€ deploy/                 â†’ Export-ready deploy scripts
â”œâ”€â”€ utils.py                â†’ Support utilities

software screenshot/        â†’ App screenshots

requirements.txt            â†’ Python dependencies
README.md                   â†’ This file

==================================================
ğŸ›  Installation

Clone and install:
------------------
git clone https://github.com/kulveenkaur25/LLm.git
cd LLm
pip install -r requirements.txt

Start the app:
--------------
python src/full_UI.py

==================================================
ğŸ“ Dataset Format

For fine-tuning (`finetune_data.xlsx`):
---------------------------------------
| question           | answer          |
|--------------------|-----------------|
| What is AI?        | AI stands for...|

For testing (`testing_data.xlsx`):
----------------------------------
| question           | ground_truth    | context     |
|--------------------|-----------------|-------------|
| What is AI?        | AI stands for...| AI is...    |

==================================================
ğŸ”¢ Supported Loss Functions for Embedding Fine-Tuning
--------------------------------------------------
- MultipleNegativesRankingLoss
- OnlineContrastiveLoss
- TripletLoss
- GISTEmbedLoss
- CoSENTLoss

==================================================
ğŸ§  LLMs You Can Fine-Tune
--------------------------------------------------
- Mistral
- Zephyr
- LLaMA
- Phi
- Flan-T5
- Custom (via editable Python code)

==================================================
ğŸ‘¤ Author

Kulveen Kaur  
MS in Applied Data Science â€“ Syracuse University  
LinkedIn: https://www.linkedin.com/in/kulveenkaur25  
Portfolio :https://kulveenkaur25.github.io/Portfolio
GitHub: https://github.com/kulveenkaur25  
Research :https://scholar.google.com/citations?hl=en&user=-7a73VsAAAAJ&view_op=list_works

==================================================
ğŸ“¸ Screenshots

Screenshots available in the `software screenshot/` folder:
- Data Collection
- Fine-tuning
- Human Evaluation
- Inference

==================================================
ğŸ“„ License

This project is licensed under the MIT License.

==================================================
